{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cca1b36-bcbc-49df-9e24-24bf5ec66770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c4d16ac-ecb2-4f42-910b-67b3b339e7d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a SparkSession with the name \"Fetch JSON Data\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fetch JSON Data\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1fc94d4-29f9-49fc-a439-b6013a266bc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the paths to the JSON files for brands, users, and receipts data\n",
    "brands_volume_path = \"/Volumes/fetch_rewards/default/fetch_data_volume/brands.json\"\n",
    "user_volume_path = \"/Volumes/fetch_rewards/default/fetch_data_volume/users.json\"\n",
    "receipts_volume_path = \"/Volumes/fetch_rewards/default/fetch_data_volume/receipts.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f91243d5-9c9b-438f-bf10-43059ab1a0b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Extraction and Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaff0f8a-692f-4923-b78c-16c53697c1a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def flatten_df(nested_df):\n",
    "    # Get the list of columns that are not nested (not of struct type)\n",
    "    flat_cols = [c[0] for c in nested_df.dtypes if c[1][:6] != 'struct']\n",
    "    # Get the list of columns that are nested (of struct type)\n",
    "    nested_cols = [c[0] for c in nested_df.dtypes if c[1][:6] == 'struct']\n",
    "\n",
    "    # Loop until there are no more nested columns\n",
    "    while nested_cols:\n",
    "        # Select flat columns and expand nested columns\n",
    "        flat_df = nested_df.select(\n",
    "            flat_cols + \n",
    "            [col(nc + '.' + c).alias(nc + '_' + c) for nc in nested_cols for c in nested_df.select(nc + '.*').columns]\n",
    "        )\n",
    "        # Update nested_df to the newly flattened DataFrame\n",
    "        nested_df = flat_df\n",
    "        # Update the list of flat columns\n",
    "        flat_cols = [c[0] for c in nested_df.dtypes if c[1][:6] != 'struct']\n",
    "        # Update the list of nested columns\n",
    "        nested_cols = [c[0] for c in nested_df.dtypes if c[1][:6] == 'struct']\n",
    "\n",
    "    return nested_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e69486b2-dcbc-45c2-b6ee-021ec40088c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the JSON file into a DataFrame\n",
    "raw_brands_df = spark.read.json(brands_volume_path)\n",
    "\n",
    "# Flatten the nested DataFrame\n",
    "brands_df = flatten_df(raw_brands_df)\n",
    "\n",
    "# Rename columns for consistency and readability\n",
    "brands_df = brands_df.withColumnRenamed('brandCode','brand_code')\\\n",
    "                        .withColumnRenamed('category','category_name')\\\n",
    "                        .withColumnRenamed('categoryCode','category_code')\\\n",
    "                        .withColumnRenamed('name','brand_name')\\\n",
    "                        .withColumnRenamed('topBrand','is_top_brand')\\\n",
    "                        .withColumnRenamed('_id_$oid','brand_id') \\\n",
    "                        .withColumnRenamed('cpg_$ref','cpg_ref')\\\n",
    "                        .withColumnRenamed('cpg_$id_$oid','cpg_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2960221a-d871-416d-b58d-4f008129b2e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "# Read the JSON file into a DataFrame\n",
    "raw_receipts_df = spark.read.json(receipts_volume_path)\n",
    "\n",
    "# Flatten the nested DataFrame\n",
    "receipts_df = flatten_df(raw_receipts_df)\n",
    "\n",
    "# Rename columns for consistency and readability\n",
    "receipts_df = receipts_df.withColumnRenamed('bonusPointsEarned','bonus_points_earned')\\\n",
    "                            .withColumnRenamed('bonusPointsEarnedReason','bonus_points_earned_reason')\\\n",
    "                            .withColumnRenamed('createDate_$date','create_date')\\\n",
    "                            .withColumnRenamed('dateScanned_$date','date_scanned')\\\n",
    "                            .withColumnRenamed('finishedDate_$date','finished_date')\\\n",
    "                            .withColumnRenamed('modifyDate_$date','modify_date')\\\n",
    "                            .withColumnRenamed('pointsAwardedDate_$date','points_awarded_date')\\\n",
    "                            .withColumnRenamed('pointsEarned','points_earned')\\\n",
    "                            .withColumnRenamed('purchaseDate_$date','purchase_date')\\\n",
    "                            .withColumnRenamed('purchasedItemCount','purchased_item_count')\\\n",
    "                            .withColumnRenamed('rewardsReceiptItemList','rewards_receipt_item_list')\\\n",
    "                            .withColumnRenamed('rewardsReceiptStatus','rewards_receipt_status')\\\n",
    "                            .withColumnRenamed('totalSpent','total_spent')\\\n",
    "                            .withColumnRenamed('userId','user_id')\\\n",
    "                            .withColumnRenamed('_id_$oid','receipt_id')\n",
    "\n",
    "# Convert columns from unix to date type\n",
    "receipts_df = receipts_df.withColumn('create_date', to_date((col('create_date') / 1000).cast('timestamp')))\\\n",
    "                         .withColumn('date_scanned', to_date((col('date_scanned') / 1000).cast('timestamp')))\\\n",
    "                         .withColumn('finished_date', to_date((col('finished_date') / 1000).cast('timestamp')))\\\n",
    "                         .withColumn('modify_date', to_date((col('modify_date') / 1000).cast('timestamp')))\\\n",
    "                         .withColumn('points_awarded_date', to_date((col('points_awarded_date') / 1000).cast('timestamp')))\\\n",
    "                         .withColumn('purchase_date', to_date((col('purchase_date') / 1000).cast('timestamp')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5e826f4-8252-4981-874a-895540f65973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# Explode the rewards_receipt_item_list array column\n",
    "exploded_receipts_df = receipts_df.withColumn(\"rewards_receipt_item\", explode(\"rewards_receipt_item_list\"))\n",
    "\n",
    "# Create a separate DataFrame with receipt_id and all the exploded columns\n",
    "receipt_items_df = exploded_receipts_df.select(\"receipt_id\", \"rewards_receipt_item.*\")\n",
    "\n",
    "# Rename columns for consistency and readability\n",
    "for col_name in receipt_items_df.columns:\n",
    "    new_col_name = ''.join(['_' + i.lower() if i.isupper() else i for i in col_name]).lstrip('_')\n",
    "    receipt_items_df = receipt_items_df.withColumnRenamed(col_name, new_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3007564-7945-4316-bec2-ee0355b64ae3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the JSON file into a DataFrame\n",
    "raw_users_df = spark.read.json(user_volume_path)\n",
    "\n",
    "# Flatten the nested DataFrame and drop any corrupt records\n",
    "users_df = flatten_df(raw_users_df).drop('_corrupt_record')\n",
    "\n",
    "# Rename columns for consistency and readability\n",
    "users_df = users_df.withColumnRenamed('signUpSource','sign_up_source')\\\n",
    "                   .withColumnRenamed('active','is_active')\\\n",
    "                   .withColumnRenamed('createdDate_$date','created_date')\\\n",
    "                   .withColumnRenamed('lastLogin_$date','last_login_date')\\\n",
    "                   .withColumnRenamed('_id_$oid','user_id')\n",
    "\n",
    "users_df = users_df.withColumn('created_date', to_date((col('created_date') / 1000).cast('timestamp')))\\\n",
    "                         .withColumn('last_login_date', to_date((col('last_login_date') / 1000).cast('timestamp')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b166f326-27aa-442e-9ea4-250998c66c06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b6fca6c-280a-44f7-8c42-a0c807f0a942",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing receipt IDs: 0\nUnique receipt IDs: 1119, Total receipt IDs: 1119\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_id</th><th>receipt_id</th><th>create_date</th><th>purchase_date</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>448</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0,
         0,
         448
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "receipt_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "create_date",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "purchase_date",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Quality check for Receipts table\n",
    "\n",
    "from pyspark.sql.functions import count, when, col\n",
    "\n",
    "# Check for unique values in primary key column\n",
    "unique_receipt_ids = receipts_df.select(\"receipt_id\").distinct().count()\n",
    "\n",
    "# Check missing value in primary key column receipt_id\n",
    "missing_receipt_ids = receipts_df.filter(col(\"receipt_id\").isNull()).count()\n",
    "print(f\"Missing receipt IDs: {missing_receipt_ids}\")\n",
    "total_receipt_ids = receipts_df.count()\n",
    "print(f\"Unique receipt IDs: {unique_receipt_ids}, Total receipt IDs: {total_receipt_ids}\")\n",
    "\n",
    "# Count nulls for specified columns\n",
    "missing_values_receipts = receipts_df.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"user_id\", \"receipt_id\", \"create_date\", \"purchase_date\"]])\n",
    "display(missing_values_receipts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865c6e11-f848-43a6-a04e-128e27f56940",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>receipt_id</th><th>barcode</th><th>quantity_purchased</th><th>item_price</th><th>points_earned</th></tr></thead><tbody><tr><td>0</td><td>3851</td><td>174</td><td>174</td><td>6014</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         3851,
         174,
         174,
         6014
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "receipt_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "barcode",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "quantity_purchased",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "item_price",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "points_earned",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>min_quantity</th><th>max_quantity</th><th>min_price</th><th>max_price</th><th>min_points</th><th>max_points</th></tr></thead><tbody><tr><td>1</td><td>17</td><td>0.00</td><td>95.84</td><td>10.0</td><td>99.9</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         17,
         "0.00",
         "95.84",
         "10.0",
         "99.9"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "min_quantity",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "max_quantity",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "min_price",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "max_price",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "min_points",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "max_points",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Quality check for Receipt Items table\n",
    "\n",
    "from pyspark.sql.functions import count, when, col, min, max\n",
    "\n",
    "# Count nulls for specified columns\n",
    "missing_values_receipt_items = receipt_items_df.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"receipt_id\", \"barcode\", \"quantity_purchased\", \"item_price\",\"points_earned\"]])\n",
    "display(missing_values_receipt_items)\n",
    "\n",
    "# Range checks for numerical columns\n",
    "numerical_columns_stats = receipt_items_df.select(\n",
    "    min(col(\"quantity_purchased\")).alias(\"min_quantity\"),\n",
    "    max(col(\"quantity_purchased\")).alias(\"max_quantity\"),\n",
    "    min(col(\"item_price\")).alias(\"min_price\"),\n",
    "    max(col(\"item_price\")).alias(\"max_price\"),\n",
    "    min(col(\"points_earned\")).alias(\"min_points\"),\n",
    "    max(col(\"points_earned\")).alias(\"max_points\")\n",
    ")\n",
    "display(numerical_columns_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b42c8ae-a322-45a5-baa0-3fc897cc0dae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing user IDs: 1\nUnique user IDs: 213, Total user IDs: 495\nDuplicate user IDs: 282\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_id</th><th>sign_up_source</th><th>is_active</th><th>created_date</th><th>last_login_date</th></tr></thead><tbody><tr><td>1</td><td>49</td><td>1</td><td>1</td><td>63</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         49,
         1,
         1,
         63
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "sign_up_source",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "is_active",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "created_date",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "last_login_date",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Quality check for Users table\n",
    "\n",
    "from pyspark.sql.functions import count, when, col\n",
    "\n",
    "# Check for unique values in primary key column\n",
    "unique_user_ids = users_df.select(\"user_id\").distinct().count()\n",
    "\n",
    "# Check missing value in primary key column user_id\n",
    "missing_user_ids = users_df.filter(col(\"user_id\").isNull()).count()\n",
    "print(f\"Missing user IDs: {missing_user_ids}\")\n",
    "total_user_ids = users_df.count()\n",
    "print(f\"Unique user IDs: {unique_user_ids}, Total user IDs: {total_user_ids}\")\n",
    "\n",
    "# Check for duplicate user IDs\n",
    "duplicate_user_ids = total_user_ids - unique_user_ids\n",
    "print(f\"Duplicate user IDs: {duplicate_user_ids}\")\n",
    "\n",
    "# Count nulls for specified columns\n",
    "missing_values_users = users_df.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"user_id\", \"sign_up_source\", \"is_active\", \"created_date\", \"last_login_date\"]])\n",
    "display(missing_values_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e05c96f-1c14-40c1-b701-ce781614fbf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing brand IDs: 0\nUnique brand IDs: 1167, Total brand IDs: 1167\nDuplicate brand IDs: 0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>brand_id</th><th>barcode</th><th>brand_code</th><th>brand_name</th><th>category_code</th><th>category_name</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>234</td><td>0</td><td>650</td><td>155</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0,
         234,
         0,
         650,
         155
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "brand_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "barcode",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "brand_code",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "brand_name",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "category_code",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "category_name",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Quality check for Brands table\n",
    "\n",
    "from pyspark.sql.functions import count, when, col\n",
    "\n",
    "# Check for unique values in primary key column\n",
    "unique_brand_ids = brands_df.select(\"brand_id\").distinct().count()\n",
    "\n",
    "# Check missing value in primary key column brand_id\n",
    "missing_brand_ids = brands_df.filter(col(\"brand_id\").isNull()).count()\n",
    "print(f\"Missing brand IDs: {missing_brand_ids}\")\n",
    "total_brand_ids = brands_df.count()\n",
    "print(f\"Unique brand IDs: {unique_brand_ids}, Total brand IDs: {total_brand_ids}\")\n",
    "\n",
    "# Check for duplicate brand IDs\n",
    "duplicate_brand_ids = total_brand_ids - unique_brand_ids\n",
    "print(f\"Duplicate brand IDs: {duplicate_brand_ids}\")\n",
    "\n",
    "# Count nulls for specified columns\n",
    "missing_values_brands = brands_df.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"brand_id\",\"barcode\",\"brand_code\",\"brand_name\", \"category_code\",\"category_name\"]])\n",
    "display(missing_values_brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5e69ecd-7039-47e1-8ada-b0bfc55bcfb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Response to questions from a business stakeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93499e27-7ca3-4d41-8abd-7ca6a8e1df1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create temporary views for the dataframes\n",
    "receipts_df.createOrReplaceTempView(\"receipts\")\n",
    "users_df.createOrReplaceTempView(\"users\")\n",
    "brands_df.createOrReplaceTempView(\"brands\")\n",
    "receipt_items_df.createOrReplaceTempView(\"receipt_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bca0033f-1cd9-4ea7-974e-ccf0057259e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>greater_average_spend</th></tr></thead><tbody><tr><td>Rejected</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Rejected"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "greater_average_spend",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#When considering average spend from receipts with 'rewardsReceiptStatus’ of ‘Accepted’ or ‘Rejected’, which is greater?\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "  CASE \n",
    "    WHEN AVG(CASE WHEN r.rewards_receipt_status = 'Accepted' THEN r.total_spent ELSE NULL END) > \n",
    "         AVG(CASE WHEN r.rewards_receipt_status = 'Rejected' THEN r.total_spent ELSE NULL END) \n",
    "    THEN 'Accepted' \n",
    "    ELSE 'Rejected' \n",
    "  END AS greater_average_spend\n",
    "FROM receipts r\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the result\n",
    "result_df = spark.sql(query)\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3e50bf8-c175-4692-af85-d95c02fb4e92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>greater_total_items_purchased</th></tr></thead><tbody><tr><td>Rejected</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Rejected"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "greater_total_items_purchased",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#When considering total number of items purchased from receipts with 'rewardsReceiptStatus’ of ‘Accepted’ or ‘Rejected’, which is greater?\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "  CASE \n",
    "    WHEN SUM(CASE WHEN r.rewards_receipt_status = 'Accepted' THEN ri.quantity_purchased ELSE 0 END) > \n",
    "         SUM(CASE WHEN r.rewards_receipt_status = 'Rejected' THEN ri.quantity_purchased ELSE 0 END) \n",
    "    THEN 'Accepted' \n",
    "    ELSE 'Rejected' \n",
    "  END AS greater_total_items_purchased\n",
    "FROM receipts r\n",
    "JOIN receipt_items ri\n",
    "ON r.receipt_id = ri.receipt_id\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the result\n",
    "result_df = spark.sql(query)\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64054fc9-91d9-469b-86af-2468445bd868",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Communication with Business Stakeholders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "599d6e1f-73d9-4090-998d-676e0b73821d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hello Team,\n",
    "\n",
    "I hope this email finds you well.\n",
    "\n",
    "As I continue analyzing and optimizing our data assets, I have a few questions and concerns that I would like to discuss:\n",
    "\n",
    "Master Dataset Availability – I am looking for a master dataset that includes key item details such as original price, original description, and other metadata attributes. Access to this data would help add context and improve the quality of our datasets.\n",
    "\n",
    "Missing Values & Data Accuracy – I have noticed a significant number of missing values in the dataset, particularly for brand_code, category_code, and barcode. This could pose challenges in ensuring data accuracy. Additionally, to support accurate database design, could you clarify the relationship between item_number, brand_code, and barcode?\n",
    "\n",
    "Brand Mapping Issues – I also found receipts containing brand_code values that do not exist in the brands table. It would be helpful to have the correct mapping between these brand codes and the brands table.\n",
    "\n",
    "Data Processing Efficiency – Processing unstructured JSON data into a structured format can be compute-intensive and time-consuming, especially at scale. I would like to explore the possibility of using a NoSQL database and compare its efficiency with our current approach.\n",
    "\n",
    "Your input will be invaluable in delivering high-quality and optimized data solutions. I appreciate your time and look forward to your insights and any additional details you can provide.\n",
    "\n",
    "Thank you for your time and cooperation.\n",
    "\n",
    "Best regards,\n",
    "DE team\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8265156797220795,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "fetch_rewards",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}